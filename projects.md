---
layout: page
title: Projects
permalink: /projects/
---

### Blue Dolphin Cloud
<div style="text-align:justify;">
    Blue Dolphin Cloud is being designed to scale massively. This project has two parts REST API and Big Data Analytics project. The API is built on NodeJS engine, and for REST API we use Restify as a framework. The cloud database is MongoDB, and for caching, we use Redis Clusters. Currently, we use Redis only in the API because it is costly. We ensure schema setup earlier using Mongoose and Casbah. Big Data analytics engine runs on Apache Spark and streaming is a fundamental component in it. I am looking into Flink as well for this. For caching I am planning to use SSD storages which are better alternatives if you are going to store humongous data. Also, the documentation engine used for this Cloud is swagger which will soon be live. Security is based on Oauth2 and on the front we use API-Gateway from Amazon to make sure crackers enjoy the fun of breaking Amazon services. I am a core engineer and the initiator of this project.
</div>
***

### SVAR
<div style="text-align:justify;">
    This product is used to assess the English speaking skills of the candidate.  I was the core engineer of this product. It is built on the top of PHP, FreePBX, and Asterisk. The product is on telephone lines, VoIP and computer. In this product, there are two modules scoring and delivery. Delivery is responsible for conducting a test. The candidate dials a number or logs in the web portal. Then he is instructed to take the test. The test is recorded, and once the exam completes, the recordings are uploaded for scoring. Scoring runs on the linear regression model. The records are compared with an ideal voice recording and based on the deviation from the perfect sound the scores are provided. I was the core engineer for this product. Maintaining the server was also an added task for me as knowledge of Asterisk is required for it, and server admins are not aware of the Asterisk tool. Managing the version control for this system, setting up a testing or new server for the product, these are the few important tasks that I carried out. I also handled client requests for this product.
</div>
***

### SVAR Tool
<div style="text-align:justify;">
    As the client requests were increasing in SVAR there was a need felt to built a tool which will help the Client team to process the query as early as possible.  I took the initiative for this product. I had built the entire backend for this product.  In this product, I also initiated the use of frameworks in SVAR system. After discussion with my manager, I took Codeigniter framework for this. This system was built on a master- slave  architecture. It linked 6 servers altogether. It had all the data collecting mechanisms. I also built some visualisations for the data. This is built on PHP, CodeIgniter, Zookepeer and mechanism used is the heartbeat.
</div>
***

### Automata
<div style="text-align:justify;">
    This product is used by the company to judge the coding skill of a candidate. Like the online judge environment, this is a tool build for compiling in a constrained environment. On the basis of the compiling parameters, the code of the test taker is judged. This is what we see in coding websites, but the added feature in this is that machine learning algorithms provide a more detailed insight. My job was to revamp the system in such a way that production and delivery system were synced up -- as, initially, separate codes were running on both the systems. For this system, I also built a Health Script which defined whether the system is working properly or not. Also, this script did a rigorous data analysis on the database. The output was designed in such a way that it can be used for visualisation.
</div>
***

### Indian Railway's visualisation engine
<div style="text-align:justify;">
    Indian Railway services have decided to update the infrastructure of the service. New technologies are introduced in the system, and a lot of data will be produced from this new infrastructure. This project aims to provide Data Visualization for that data.  I worked on many types of visualizations which improved Human Computer Interaction. Some of them are Train Delay Charts, Time Table, Intersection on arrival and departure, Stacked and Bar Chart and Heat Map. The were all written in Data Driven Document script (D3.js), and data is collected by Hadoop crunching.
</div>
***

### Sentiment Analysis & Information Extraction
<div style="text-align:justify;">
    This project was research-oriented and had two phases. In the first step, I studied three NLP sentiment analysis algorithms which are Naive Bayes, Linear Regression, and Support Vector Machine. Along with that a lot of other things were involved like TF-IDF, port stemmers, data clean up and many more things. The three algorithms were studied on both IMDb movie reviews and Twitter tweets. The best results were given by Support Vector Machine. In the second phase, we introduced Part of Speech Tagger. Next, we build a web crawler which could documents from various sources and pass it to machine learned system. Then the system used to tag the speech and provide the sentiments for the nouns in the documents. Having adjectives also in the speech, we could describe the nouns as well. IMDb was better source for using part of speech tagging than Twitter tweets.
</div>
***
